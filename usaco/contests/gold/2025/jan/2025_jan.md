# USACO Gold 2025 Jan

## 1. Median Heap
For $O(NQ)$: consider a dp where each node has three states: $dp[i][0]$, if the median approximation for the subtree of $i$ is less than the target median $m$, $dp[i][1]$, if the approximation is equal to $m$, and $dp[i][2]$ if the approximation is greater than $m$.

This can be computed in $O(N)$ per query. Define the dp base cases $b[i]$ for node $i$, $b[i][0]=0$ if $a_i<m$ and $c_i$ otherwise; $b[i][1]=0$ if $a_i=m$ and $c_i$ otherwise; $b[i][2]=0$ if $a_i>m$ and $c_i$ otherwise. Then we evaluate all $3^3$ combinations of $b[i]$, $dp[2i]$, and $dp[2i+1]$ to get $dp[i]$.

To speedup the solution: since $b_i$ (and thus $dp_i$) is computed by looking at the value of $a_i$ relative to $m$, then if queries are processed offline in decreasing value of $m$, then $b_i$ changes at most twice â€” when $m=a_i$ and when $m<a_i$. Updating $b_i$ results in an update of the dp values of $i$ and all its ancestors, at most $\lceil{log_2N}\rceil$ nodes. So across all queries the total time complexity is $O(NlogN+QlogQ)$.

## 2. Reachable Pairs
Only problem I solved in contest, lol. 

Let $G$ be the original graph. When $s_i=0$, then we just delete the node; this will never add any new edges. These operations can be processed with DSU in reverse. When $s_i=1$, then all of the adjacent nodes will still be reachable from each other for all future operations. This property is not transitive.

For $s_i=1$, then we effectively don't change the reachability of adjacent nodes, so we actually don't even need to bother deleting this node. Only when $s_i=0$ does the reachability change, so ignore those for now. First, use DSU to merge all nodes satisfying $s_i=1$; this is the base graph (a more intuitive reason for this will become apparent later). Some of the nodes in this base graph might not exist in certain timestamps, so also store the amount of nodes that don't exist yet. We'll update this counter as we iterate in reverse over timestamps.

Since we have gotten rid of $s_i=1$, then we only process nodes satisfying $s_i=0$. For each of these nodes, we first unite it with all adjacent nodes $j$ in $G$, that currently exist (so $j>i$). 

We are forgetting some adjacent nodes however, specifically the ones that were made adjacent to this node through the deletion of a node $j$ satisfying $s_j=1$. All these nodes must have been adjacent to $i$ in $G$. So now, we can also unite this node with all adjacent nodes $j$ in $G$, such that $s_j=1$ and $j<i$ (doesn't exist yet). This is the reason that we store all the nodes that don't exist, because they are helpful in finding the other adjacent nodes.

Time complexity is $O(M\alpha(N))$.

## 3. Photo Op
Consider the set of all $x_i$ currently posing. The shortest distance is constructed by the following procedure:
 - We go to $x_i$ in one segment and then some point on the y-axis in the second segment. Then we go along the y-axis to reach $Y$ for the third segment.

 mention the small side cases

For all $x_i<X$, we can assume that we traverse along the left of segment $i$ from $x_i$ to the y-axis (so traverse between segments $i$ and $i-1$), while for $x_i>X$, we can assume that we traverse along the right of segment $i$ (between $i$ and $i+1$).

We maintain the shortest distance to $Y$ through each $x_i$, and retrieve the minimum with a multiset. For some fixed $x_i$, the range of points on the y-axis that we might go to for our second segment is bounded by the maximum y-coordinate $y_j$ of a segment $x_j<x_i$, and the minimum y-coordinate $y_j$ of a segment $x_j>x_i$. Retrieve these with a segment tree after coordinate compression (there are alternate methods, but a segtree is the most implementation-friendly imo). If the range is empty then no second segment can be built, and we don't have to process this $x_i$ anymore. Otherwise, it's pretty clear that our second segment is from $x_i$ to one of the endpoints of the y-range, and we can update the distance multiset easily.

Therefore, we have a solution in $O(NlogN)$. When creating a new segment, update all y-ranges that it interferes with. These indices form a range. It's clear that for all indices contained inside the range that are not the endpoints, their y-ranges become nonempty and we can delete them. This means that out all indices of the range, we keep exactly two (the endpoints) for future consideration and remove the rest. Thus, the runtime is $O(NlogN)$.